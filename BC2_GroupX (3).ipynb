{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BC2- Predicting Cancellations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flask\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b34931d0a30d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from joblib import dump\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler, StandardScaler,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import graphviz\n",
    "import imblearn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Defining PROJECT_ROOT\n",
    "PROJECT_ROOT = Path(os.path.abspath('')).resolve().parents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import set_option\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from mlxtend.plotting import plot_confusion_matrix \n",
    "from mlxtend.classifier import StackingClassifier \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('H2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Country'], axis=1,inplace = True)\n",
    "# Since you dont have this information prior to the check-in\n",
    "\n",
    "df.drop(['IsCanceled'], axis=1,inplace = True)\n",
    "#Since we will try to predict also the not show clients\n",
    "\n",
    "df.drop(['DepositType'], axis=1, inplace = True)\n",
    "\n",
    "df.drop(columns = ['ArrivalDateYear','ArrivalDateMonth','ArrivalDateDayOfMonth','ArrivalDateWeekNumber'], axis=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the target variable\n",
    "df['ReservationStatus'] =df['ReservationStatus'].astype('category').cat.codes\n",
    "\n",
    "df['ReservationStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check continuos correlations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "cor = df[['ReservationStatus','LeadTime','StaysInWeekendNights','StaysInWeekNights',\n",
    "          'Adults','Children','Babies','PreviousCancellations',\n",
    "          'PreviousBookingsNotCanceled','BookingChanges','DaysInWaitingList','ADR',\n",
    "         'RequiredCarParkingSpaces','TotalOfSpecialRequests']].corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cor_heatmap(cor):\n",
    "    plt.figure(figsize=(13,7))\n",
    "    sns.heatmap(data = cor, annot = True, cmap = 'YlGnBu', fmt = '.1')\n",
    "    plt.show\n",
    "    \n",
    "\n",
    "cor_heatmap(cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check categorical correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ax = sns.countplot(x=\"Agent\", hue=\"ReservationStatus\", data=df[df['Agent']=='          9'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = sns.countplot(x=\"ArrivalDateWeekNumber\", hue=\"ReservationStatus\", data=df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all').transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill missing data in Children\n",
    "df['Children'].fillna(df['Children'].median(), inplace=True)\n",
    "df['Children'] = df['Children'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_metric_features= ['AssignedRoomType','CustomerType',\n",
    "                      'DistributionChannel','IsRepeatedGuest','MarketSegment','Meal',\n",
    "                      'ReservationStatusDate','ReservedRoomType','Agent','Company']\n",
    "metric_features = df.columns.drop(non_metric_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['ReservationStatus'])\n",
    "y = df[['ReservationStatus']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=15\n",
    "                                                    , stratify=y)\n",
    "\n",
    "combine = [X_train,X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical\n",
    "- Lead time- nao apagar\n",
    "- StaysInWeekendNights - apagar o 14\n",
    "- StaysInWeekNights - apagar o 24\n",
    "- Adults - nao apagar\n",
    "- Children - nao apagar\n",
    "- Babies - apagar o 10\n",
    "- PreviousCancellations - apagar no 10\n",
    "- PreviousBookingsNotCanceled - apagar no 34\n",
    "- BookingChanges - apagar no 12\n",
    "- DaysInWaitingList - apagar no 260\n",
    "- ADR - apagar no 400 \n",
    "- RequiredCarParkingSpaces - Nao apagar\n",
    "- TotalOfSpecialRequests - Nao apagar\n",
    "\n",
    "**13 numerical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist = px.histogram(X_train, x=X_train['LeadTime'], color_discrete_sequence=['darkseagreen'], template='plotly_white')\n",
    "# hist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lof = LocalOutlierFactor(n_neighbors=20, contamination = 0.03)\n",
    "result=lof.fit_predict(Xy[metric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_index= np.where(result==-1)\n",
    "outliers_index=outliers_index[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_features_1 = Xy[metric_features].drop(Xy[metric_features].index[outliers_index],axis=0)\n",
    "\n",
    "df_2 = Xy.drop(Xy.index[outliers_index],axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage of data kept after removing outliers:'\n",
    "      , np.round(metric_features_1.shape[0] /Xy[metric_features].shape[0], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Xy.iloc[:,:-1]\n",
    "y_train = Xy.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical\n",
    "\n",
    "Eu acho que nestas temos de ver é como é que reduzimos o numero de categorias\n",
    "\n",
    "- ArrivalDateYear - Nao apagar\n",
    "- ArrivalDateMonth - Nao apagar\n",
    "- ArrivalDateWeekNumber - Nao apagar\n",
    "- ArrivalDateDayOfMonth - Nao apagar\n",
    "- Meal - Nao apagar / FB\n",
    "- MarketSegment - Undefined\n",
    "- DistributionChannel - Undefined and GDS\n",
    "- IsRepeatedGuest - variavel binária\n",
    "- ReservedRoomType - Juntar as categorias\n",
    "- AssignedRoomType - Igual ao de cima\n",
    "- Agent - Nao apagar\n",
    "- Company - Nao apagar\n",
    "- CustomerType - Nao apagar\n",
    "\n",
    "**13 categorical**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hist = px.histogram(X_train, x=X_train['Agent'], color_discrete_sequence=['darkseagreen'], template='plotly_white')\n",
    "# hist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = sns.countplot(x=\"Meal\", hue=\"ReservationStatus\", data=X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 - cancelar\n",
    "1 - check out\n",
    "2 - no show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine = [X_train,X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " months = {\n",
    "            'January' : 1,\n",
    "            'February' : 2,\n",
    "            'March' : 3,\n",
    "            'April' : 4,\n",
    "            'May' : 5,\n",
    "            'June' : 6,\n",
    "            'July' : 7,\n",
    "            'August' : 8,\n",
    "            'September' : 9, \n",
    "            'October' : 10,\n",
    "            'November' : 11,\n",
    "            'December' : 12\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset in combine:\n",
    "#     dataset['ArrivalDateMonth'] = dataset['ArrivalDateMonth'].map(months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset[\"Meal\"] = dataset[\"Meal\"].map({\"BB       \":'BB',\"SC       \":'SC','FB       ':'HB/FB', 'HB       ':'HB/FB'})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['MarketSegment'] = np.where(dataset['MarketSegment'] == 'Undefined','Other', dataset['MarketSegment'])\n",
    "    dataset['MarketSegment'] = np.where(dataset['MarketSegment'] == 'Aviation','Other', dataset['MarketSegment']) \n",
    "    dataset['MarketSegment'] = np.where(dataset['MarketSegment'] == 'Complementary','Other', dataset['MarketSegment']) \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['DistributionChannel'] = np.where(dataset['DistributionChannel'] == 'Undefined','Other', dataset['DistributionChannel'])\n",
    "    dataset['DistributionChannel'] = np.where(dataset['DistributionChannel'] == 'GDS','Other', dataset['DistributionChannel']) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Agent'] = np.where(dataset['Agent'] != '       NULL','1', dataset['Agent'])\n",
    "    dataset['Agent'] = np.where(dataset['Agent'] == '       NULL','0', dataset['Agent'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Company'] = np.where(dataset['Company'] != '       NULL','1', dataset['Company'])\n",
    "    dataset['Company'] = np.where(dataset['Company'] == '       NULL','0', dataset['Company'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Nr People'] = dataset['Adults'] + dataset['Children'] + dataset['Babies']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    X_train['Totalnights']= X_train.StaysInWeekNights + X_train.StaysInWeekendNights\n",
    "    X_test['Totalnights']= X_test.StaysInWeekNights + X_test.StaysInWeekendNights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_features = ['LeadTime', 'StaysInWeekendNights', 'StaysInWeekNights', 'Adults',\n",
    "       'Children', 'Babies', 'PreviousCancellations',\n",
    "       'PreviousBookingsNotCanceled', 'BookingChanges', 'DaysInWaitingList',\n",
    "       'ADR', 'RequiredCarParkingSpaces', 'TotalOfSpecialRequests']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler1 = StandardScaler()\n",
    "# scaled_feat_X_train = scaler1.fit_transform(X_train[metric_features])\n",
    "# X_train_scaled = pd.DataFrame(scaled_feat_X_train, columns =X_train[metric_features].columns )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler2 = StandardScaler()\n",
    "# scaled_feat_X_test = scaler2.fit_transform(X_test[metric_features])\n",
    "# X_test_scaled = pd.DataFrame(scaled_feat_X_test, columns =X_test[metric_features].columns )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Enconding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode categorical features\n",
    "ohc_features = [#'ArrivalDateYear', 'ArrivalDateMonth', 'ArrivalDateWeekNumber', 'ArrivalDateDayOfMonth'\n",
    "                'Meal', \n",
    "                'MarketSegment', 'DistributionChannel','IsRepeatedGuest','ReservedRoomType','AssignedRoomType',\n",
    "               'Agent','Company','CustomerType']\n",
    "\n",
    "ohc = OneHotEncoder(sparse=False, drop= 'first')\n",
    "df_ohc_train = pd.DataFrame(ohc.fit_transform(X_train[ohc_features]),\n",
    "index=X_train.index,\n",
    "columns=ohc.get_feature_names(ohc_features))\n",
    "#X_train  = pd.concat([X_train,df_ohc_train],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohc = OneHotEncoder(sparse=False,drop= 'first' )\n",
    "df_ohc_test = pd.DataFrame(ohc.fit_transform(X_test[ohc_features]),\n",
    "index=X_test.index,\n",
    "columns=ohc.get_feature_names(ohc_features))\n",
    "#X_test  = pd.concat([X_test,df_ohc_test],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.reset_index(inplace = True, drop = True)\n",
    "X_test.reset_index(inplace = True, drop = True)\n",
    "df_ohc_test.reset_index(inplace = True, drop = True)\n",
    "df_ohc_train.reset_index(inplace = True, drop = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[metric_features] = X_train_scaled\n",
    "# X_test[metric_features] = X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train  = pd.concat([X_train,df_ohc_train],axis = 1)\n",
    "X_test  = pd.concat([X_test,df_ohc_test],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.drop(columns = ohc_features,inplace = True)\n",
    "X_test.drop(columns = ohc_features,inplace = True)\n",
    "\n",
    "X_test.drop('ReservationStatusDate',axis = 1, inplace = True)\n",
    "X_train.drop('ReservationStatusDate',axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spot-Check Algorithms\n",
    "# def GetBasedModel():\n",
    "#     basedModels = []\n",
    "#     basedModels.append(('LR'   , LogisticRegression())) \n",
    "#     basedModels.append(('LDA'  , LinearDiscriminantAnalysis()))\n",
    "#     basedModels.append(('KNN'  , KNeighborsClassifier()))\n",
    "#     basedModels.append(('CART' , DecisionTreeClassifier()))\n",
    "#     basedModels.append(('NB'   , GaussianNB()))\n",
    "#     basedModels.append(('AB'   , AdaBoostClassifier()))\n",
    "#     basedModels.append(('GBM'  , GradientBoostingClassifier()))\n",
    "#     basedModels.append(('RF'   , RandomForestClassifier()))\n",
    "#     basedModels.append(('ET'   , ExtraTreesClassifier()))\n",
    "\n",
    "    \n",
    "#     return basedModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def BasedLine2(X_train, y_train,models):\n",
    "#     # Test options and evaluation metric\n",
    "#     num_folds = 10\n",
    "#     scoring = 'accuracy'\n",
    "\n",
    "#     results = []\n",
    "#     names = []\n",
    "#     for name, model in models:\n",
    "#         kfold = StratifiedKFold(n_splits=num_folds, random_state=SEED)\n",
    "#         cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "#         results.append(cv_results)\n",
    "#         names.append(name)\n",
    "#         msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "#         print(msg)\n",
    "        \n",
    "#     return names, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PlotBoxR(object):\n",
    "    \n",
    "    \n",
    "#     def __Trace(self,nameOfFeature,value): \n",
    "    \n",
    "#         trace = go.Box(\n",
    "#             y=value,\n",
    "#             name = nameOfFeature,\n",
    "#             marker = dict(\n",
    "#                 color = 'rgb(0, 128, 128)',\n",
    "#             )\n",
    "#         )\n",
    "#         return trace\n",
    "\n",
    "#     def PlotResult(self,names,results):\n",
    "        \n",
    "#         data = []\n",
    "\n",
    "#         for i in range(len(names)):\n",
    "#             data.append(self.__Trace(names[i],results[i]))\n",
    "\n",
    "\n",
    "#         py.iplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEED = 7\n",
    "# np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# models = GetBasedModel()\n",
    "# names,results = BasedLine2(X_train, y_train,models)\n",
    "# #PlotBoxR().PlotResult(names,results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the Random Forest model\n",
    "# rf = RandomForestClassifier(random_state=0,class_weight='auto')\n",
    "\n",
    "# # Define the grid to explore\n",
    "# grid = {\n",
    "#     \"criterion\": [\"entropy\", \"gini\"],\n",
    "#     \"max_depth\": [3, 6, 9],\n",
    "#     \"min_samples_split\": [0.005, 0.01, 0.05],\n",
    "#     \"max_features\": [None, \"sqrt\"],\n",
    "#     \"class_weight\": [None, 'balanced', {0: 1, 1: 2}]\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instatiating GridSearch\n",
    "# splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "# gscv = GridSearchCV(rf, grid, cv=splitter, scoring='f1_weighted', refit=True, verbose=-1, n_jobs=-1)\n",
    "\n",
    "# # Get ID of grid search\n",
    "# # id_num = input(\"Insert GridSearch ID number: \")\n",
    "# id_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grid Search and model training\n",
    "# #gscv.fit(X_train, y_train)\n",
    "\n",
    "# # Saving cv_results for specific Grid Search run\n",
    "# #out_path = os.path.join(PROJECT_ROOT, 'analysis')\n",
    "# #score_summary = pd.DataFrame(gscv.cv_results_).sort_values(by=\"mean_test_score\", ascending=False)\n",
    "# #score_summary.to_csv(os.path.join(out_path, 'grid_search_results{}.csv'.format(id_num)))\n",
    "\n",
    "# # Saving best model\n",
    "# best_rf = gscv.best_estimator_\n",
    "# dump(best_rf, os.path.join(out_path, 'best_random_forest{}.joblib'.format(id_num)))\n",
    "\n",
    "# # Get test set y_pred and evaluate on precision\n",
    "# y_test_pred = best_rf.predict(X_test)\n",
    "\n",
    "# print(\"The best model has a mean cross-validated precision of {0:.3f} and a test set precision of {1:.3f}\".\\\n",
    "#       format(gscv.best_score_, precision_score(y_test, y_test_pred,average = 'micro')))\n",
    "# print(\"\\nThe hyper-parameters selected are:\\n\", gscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"The best model has a mean cross-validated precision of {0:.3f} and a test set precision of {1:.3f}\".\\\n",
    "#       format(gscv.best_score_, precision_score(y_test, y_test_pred,average = 'micro')))\n",
    "# print(\"\\nThe hyper-parameters selected are:\\n\", gscv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= X_train[['LeadTime', 'StaysInWeekendNights', 'StaysInWeekNights', 'Adults',\n",
    "       'Children', 'Babies', 'PreviousCancellations',\n",
    "       'PreviousBookingsNotCanceled', 'BookingChanges', 'DaysInWaitingList',\n",
    "       'ADR', 'RequiredCarParkingSpaces', 'TotalOfSpecialRequests',\n",
    "       'Nr People', 'Totalnights', 'Meal_HB/FB', 'Meal_SC',\n",
    "       'MarketSegment_Direct', 'MarketSegment_Groups',\n",
    "       'MarketSegment_Offline TA/TO', 'MarketSegment_Online TA',\n",
    "       'MarketSegment_Other', 'DistributionChannel_Direct',\n",
    "       'DistributionChannel_Other', 'DistributionChannel_TA/TO',\n",
    "       'IsRepeatedGuest_1','Agent_1', 'Company_1',\n",
    "       'CustomerType_Group', 'CustomerType_Transient',\n",
    "       'CustomerType_Transient-Party']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= X_test[['LeadTime', 'StaysInWeekendNights', 'StaysInWeekNights', 'Adults',\n",
    "       'Children', 'Babies', 'PreviousCancellations',\n",
    "       'PreviousBookingsNotCanceled', 'BookingChanges', 'DaysInWaitingList',\n",
    "       'ADR', 'RequiredCarParkingSpaces', 'TotalOfSpecialRequests',\n",
    "       'Nr People', 'Totalnights', 'Meal_HB/FB', 'Meal_SC',\n",
    "       'MarketSegment_Direct', 'MarketSegment_Groups',\n",
    "       'MarketSegment_Offline TA/TO', 'MarketSegment_Online TA',\n",
    "       'MarketSegment_Other', 'DistributionChannel_Direct',\n",
    "       'DistributionChannel_Other', 'DistributionChannel_TA/TO',\n",
    "       'IsRepeatedGuest_1','Agent_1', 'Company_1',\n",
    "       'CustomerType_Group', 'CustomerType_Transient',\n",
    "       'CustomerType_Transient-Party']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling = {0:36124,\n",
    "#             1:36124,\n",
    "#             2:9000\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# smote = SMOTE(sampling_strategy=sampling, k_neighbors = 5)\n",
    "# X_sm, y_sm = smote.fit_sample(X_train, y_train)\n",
    "\n",
    "# X_train = X_sm\n",
    "# y_train = y_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# y_test['ReservationStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and assess model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion='entropy', max_depth=200, max_features=None,\n",
    "                       min_samples_split=0.005, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "RF_score = rf.score(X_test,y_test)\n",
    "RF_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_score = rf.score(X_train,y_train)\n",
    "RF_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test set y_pred and evaluate on precision\n",
    "y_test_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test set classification report\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test set confusion matrix\n",
    "pd.DataFrame(data=confusion_matrix(y_test, y_test_pred), \n",
    "             index=pd.Index(y_train.unique(), name=\"True\"), \n",
    "             columns=pd.Index(y_train.unique(), name=\"Pred\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "import itertools\n",
    " \n",
    "def plot_confusion_matrix(cm, classes, normalize = False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Greens): # can change color \n",
    "    plt.figure(figsize = (10, 10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, size = 24)\n",
    "    plt.colorbar(aspect=4)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, size = 14)\n",
    "    plt.yticks(tick_marks, classes, size = 14)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    # Label the plot\n",
    "    for i, j in itertools.product(range(cm.shape[0]),   range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), \n",
    "             fontsize = 20,\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.grid(None)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', size = 18)\n",
    "    plt.xlabel('Predicted label', size = 18)\n",
    "    \n",
    "    \n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plot_confusion_matrix(cm, classes = ['0 - Cancelled', '1 - Check-out', '2 - No show '],\n",
    "                      title = 'Prediction Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Feature Importance plot\n",
    "sns.set()\n",
    "\n",
    "# data\n",
    "feature_names = X_train.columns\n",
    "feature_importances = pd.Series(rf.feature_importances_, index=feature_names).\\\n",
    "    sort_values(ascending=False)\n",
    "\n",
    "# figure\n",
    "fig = plt.figure(figsize=(19,5))\n",
    "\n",
    "# axis\n",
    "plt.bar(x=feature_importances.index, height=feature_importances.values)\n",
    "\n",
    "# properties\n",
    "plt.ylabel(\"Gini importance\")  # The importance of a feature is computed as the (normalized) total reduction of the \n",
    "                               # criterion brought by that feature. It is also known as the Gini importance.\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Decision Tree Feature Importance\", fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickl = {'model': rf}\n",
    "pickle.dump( pickl, open( 'model_file' + \".p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
